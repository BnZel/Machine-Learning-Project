{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Dense,GlobalAveragePooling2D\n",
    "from keras.applications import MobileNet\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.mobilenet import preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.applications.vgg16 import VGG16 # load VGG16 model from keras\n",
    "from keras.preprocessing.image import load_img # Using images library\n",
    "from keras.preprocessing.image import img_to_array # # convert image pixels to numpy for specific manipulations\n",
    "from keras.applications.vgg16 import preprocess_input # to prepare for new input\n",
    "from keras.applications.vgg16 import decode_predictions # for reporting probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 225 images belonging to 5 classes.\n",
      "Found 48 images belonging to 5 classes.\n",
      "Batch shape=(32, 224, 224, 3), min=-123.680, max=151.061\n",
      "Batch shape=(32, 224, 224, 3), min=-123.680, max=151.061\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "# prepare an iterators for each dataset\n",
    "train_it = train_datagen.flow_from_directory('data/images/train',\n",
    "                                     target_size=(224,224),\n",
    "                                     color_mode='rgb',\n",
    "                                     batch_size=32,\n",
    "                                     class_mode='categorical',\n",
    "                                     shuffle=True)\n",
    "\n",
    "validate_it = train_datagen.flow_from_directory('data/images/validate',\n",
    "                                     target_size=(224,224),\n",
    "                                     color_mode='rgb',\n",
    "                                     batch_size=32,\n",
    "                                     class_mode='categorical',\n",
    "                                     shuffle=True)\n",
    "\n",
    "train_batchX, train_batchy = train_it.next()\n",
    "print('Batch shape=%s, min=%.3f, max=%.3f' % (train_batchX.shape, train_batchX.min(), train_batchX.max()))\n",
    "validate_batchX, validate_batchy = validate_it.next()\n",
    "print('Batch shape=%s, min=%.3f, max=%.3f' % (validate_batchX.shape, validate_batchX.min(), validate_batchX.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifying only weapons \n",
    "vgg16_model = VGG16(weights=\"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "seq_model = Sequential()\n",
    "\n",
    "# iterate all layers in vgg16 to sequential for custom modification\n",
    "for layer in vgg16_model.layers:\n",
    "    seq_model.add(layer)\n",
    "    \n",
    "seq_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.Dense at 0x1e528012508>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1000 categories, pop off output layer to work only specific categories\n",
    "seq_model._layers.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze weights to prevent constantly updating weights\n",
    "for layer in seq_model._layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_model.add(Dense(5, activation='softmax')) # 5 categories \n",
    "\n",
    "# seq_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "7/7 [==============================] - 2s 285ms/step - loss: 1.5170 - accuracy: 0.7617 - val_loss: 1.5992 - val_accuracy: 0.2500\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 2s 231ms/step - loss: 1.5063 - accuracy: 0.8497 - val_loss: 1.6041 - val_accuracy: 0.2083\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 2s 220ms/step - loss: 1.4906 - accuracy: 0.9378 - val_loss: 1.5970 - val_accuracy: 0.1875\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 2s 234ms/step - loss: 1.4766 - accuracy: 0.9171 - val_loss: 1.6111 - val_accuracy: 0.1667\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 2s 237ms/step - loss: 1.4784 - accuracy: 0.9223 - val_loss: 1.5664 - val_accuracy: 0.2292\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 2s 255ms/step - loss: 1.4552 - accuracy: 0.9509 - val_loss: 1.5899 - val_accuracy: 0.2708\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 2s 220ms/step - loss: 1.4458 - accuracy: 0.9482 - val_loss: 1.6083 - val_accuracy: 0.2917\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 2s 220ms/step - loss: 1.4278 - accuracy: 0.9482 - val_loss: 1.6204 - val_accuracy: 0.2500\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 2s 218ms/step - loss: 1.4282 - accuracy: 0.9430 - val_loss: 1.5989 - val_accuracy: 0.2500\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 2s 254ms/step - loss: 1.4085 - accuracy: 0.9509 - val_loss: 1.5849 - val_accuracy: 0.2500\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 2s 215ms/step - loss: 1.4171 - accuracy: 0.9444 - val_loss: 1.5850 - val_accuracy: 0.2708\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 2s 254ms/step - loss: 1.3958 - accuracy: 0.9286 - val_loss: 1.6002 - val_accuracy: 0.2708\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 2s 246ms/step - loss: 1.3771 - accuracy: 0.9637 - val_loss: 1.5609 - val_accuracy: 0.2708\n",
      "Epoch 14/20\n",
      "3/7 [===========>..................] - ETA: 0s - loss: 1.3708 - accuracy: 0.9375"
     ]
    }
   ],
   "source": [
    "seq_model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "# Adam optimizer\n",
    "# loss function will be categorical cross entropy\n",
    "# evaluation metric will be accuracy\n",
    "\n",
    "step_size_train = train_it.n//train_it.batch_size\n",
    "history = seq_model.fit_generator(generator=train_it,\n",
    "                                  validation_data=validate_it,\n",
    "                                  validation_freq=1,\n",
    "                                  steps_per_epoch=step_size_train,\n",
    "                                  shuffle=True,\n",
    "                                  epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO PREDICT PROPERLY YOU NEED TO FEED IT AN IMAGE THAT IS NOT IN THE VALIDATION OR TEST!\n",
    "prediction = seq_model.predict(validate_batchX)\n",
    "\n",
    "# convert the probabilities to class labels\n",
    "#label = decode_predictions(pred)\n",
    "\n",
    "for row in range(len(prediction)):\n",
    "    biggest = np.argmax(prediction[row])\n",
    "    for val in range(len(prediction[row])):\n",
    "        if(val == biggest):\n",
    "            prediction[row][val] = 1.\n",
    "        else:\n",
    "            prediction[row][val] = 0.\n",
    "\n",
    "# retrieve the most likely result, e.g. highest probability\n",
    "test_prediction = prediction == validate_batchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.0\n"
     ]
    }
   ],
   "source": [
    "# HOW MANY OF THE TESTS WERE WRONG\n",
    "print((np.sum(test_prediction % 2 == 0))/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
