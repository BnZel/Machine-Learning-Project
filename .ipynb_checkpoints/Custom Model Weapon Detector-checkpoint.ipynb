{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Dense,GlobalAveragePooling2D\n",
    "from keras.applications import MobileNet\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.mobilenet import preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# from keras.applications.vgg16 import VGG16 # load VGG16 model from keras\n",
    "# from keras.preprocessing.image import load_img # Using images library\n",
    "# from keras.preprocessing.image import img_to_array # # convert image pixels to numpy for specific manipulations\n",
    "# from keras.applications.vgg16 import preprocess_input # to prepare for new input\n",
    "# from keras.applications.vgg16 import decode_predictions # for reporting probabilities\n",
    "\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "\n",
    "#For Keras\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Model, load_model, save_model, Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Input, Masking, TimeDistributed, LSTM, Conv1D\n",
    "from keras.layers import GRU, Bidirectional, BatchNormalization, Reshape\n",
    "from keras.optimizers import Adam\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 225 images belonging to 5 classes.\n",
      "Found 48 images belonging to 5 classes.\n",
      "Batch shape=(32, 224, 224, 3), min=-1.000, max=1.000\n",
      "Batch shape=(32, 224, 224, 3), min=-1.000, max=1.000\n"
     ]
    }
   ],
   "source": [
    "# refer to deep learning book page 12 \"introduction to convets\"\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# prepare an iterators for each dataset\n",
    "train_it = train_datagen.flow_from_directory('data/images/train',\n",
    "                                     target_size=(224,224),\n",
    "                                     color_mode='rgb',\n",
    "                                     batch_size=32,\n",
    "                                     class_mode='categorical',\n",
    "                                     shuffle=True)\n",
    "\n",
    "validate_it = train_datagen.flow_from_directory('data/images/validate',\n",
    "                                     target_size=(224,224),\n",
    "                                     color_mode='rgb',\n",
    "                                     batch_size=32,\n",
    "                                     class_mode='categorical',\n",
    "                                     shuffle=True)\n",
    "\n",
    "train_batchX, train_batchy = train_it.next()\n",
    "print('Batch shape=%s, min=%.3f, max=%.3f' % (train_batchX.shape, train_batchX.min(), train_batchX.max()))\n",
    "validate_batchX, validate_batchy = validate_it.next()\n",
    "print('Batch shape=%s, min=%.3f, max=%.3f' % (validate_batchX.shape, validate_batchX.min(), validate_batchX.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_17 (Conv2D)           (None, 222, 222, 200)     5600      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 111, 111, 200)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 109, 109, 128)     230528    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 54, 54, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 52, 52, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 26, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 24, 24, 64)        73792     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 64)                589888    \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 24)                1560      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 5)                 125       \n",
      "=================================================================\n",
      "Total params: 1,049,077\n",
      "Trainable params: 1,049,077\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "# NOTE:\n",
    "# not sure what second parameter specifically does (#,#) \n",
    "# specify inputshapes 3rd param\n",
    "# Conv2D --> (#,#) strides ?\n",
    "# MaxPooling2D --> (#,#) pool size ?\n",
    "# either adjust nodes or add layers and epochs for better results.. \n",
    "\n",
    "model.add(layers.Conv2D(200, (3, 3), \n",
    "          activation='relu',\n",
    "          input_shape=(224, 224, 3)))\n",
    "\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "\n",
    "model.add(layers.Dense(24, activation='relu'))\n",
    "\n",
    "model.add(layers.Dense(5, activation='softmax')) # 5 categories\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adam optimizer\n",
    "# loss function will be categorical cross entropy\n",
    "# evaluation metric will be accuracy\n",
    "model.compile(\n",
    "    optimizer='Adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/45\n",
      "7/7 [==============================] - 66s 9s/step - loss: 1.5073 - accuracy: 0.3731\n",
      "Epoch 2/45\n",
      "7/7 [==============================] - 77s 11s/step - loss: 1.4707 - accuracy: 0.4152 - val_loss: 1.6127 - val_accuracy: 0.2292\n",
      "Epoch 3/45\n",
      "7/7 [==============================] - 54s 8s/step - loss: 1.4475 - accuracy: 0.3889 - val_loss: 1.6127 - val_accuracy: 0.2292\n",
      "Epoch 4/45\n",
      "7/7 [==============================] - 77s 11s/step - loss: 1.4958 - accuracy: 0.3170 - val_loss: 1.6516 - val_accuracy: 0.1458\n",
      "Epoch 5/45\n",
      "7/7 [==============================] - 63s 9s/step - loss: 1.3944 - accuracy: 0.4093 - val_loss: 1.6516 - val_accuracy: 0.1458\n",
      "Epoch 6/45\n",
      "7/7 [==============================] - 67s 10s/step - loss: 1.4282 - accuracy: 0.3679 - val_loss: 1.6050 - val_accuracy: 0.2292\n",
      "Epoch 7/45\n",
      "7/7 [==============================] - 64s 9s/step - loss: 1.5303 - accuracy: 0.4249 - val_loss: 1.6050 - val_accuracy: 0.2292\n",
      "Epoch 8/45\n",
      "7/7 [==============================] - 66s 9s/step - loss: 1.4842 - accuracy: 0.4093 - val_loss: 1.6204 - val_accuracy: 0.2292\n",
      "Epoch 9/45\n",
      "7/7 [==============================] - 63s 9s/step - loss: 1.4648 - accuracy: 0.4301 - val_loss: 1.6204 - val_accuracy: 0.2292\n",
      "Epoch 10/45\n",
      "7/7 [==============================] - 67s 10s/step - loss: 1.3563 - accuracy: 0.4249 - val_loss: 2.9819 - val_accuracy: 0.2292\n",
      "Epoch 11/45\n",
      "7/7 [==============================] - 77s 11s/step - loss: 1.4524 - accuracy: 0.4196 - val_loss: 2.9819 - val_accuracy: 0.2292\n",
      "Epoch 12/45\n",
      "7/7 [==============================] - 67s 10s/step - loss: 1.4295 - accuracy: 0.4198 - val_loss: 1.6374 - val_accuracy: 0.2292\n",
      "Epoch 13/45\n",
      "7/7 [==============================] - 76s 11s/step - loss: 1.4311 - accuracy: 0.3750 - val_loss: 1.6374 - val_accuracy: 0.2292\n",
      "Epoch 14/45\n",
      "7/7 [==============================] - 58s 8s/step - loss: 1.4223 - accuracy: 0.4321 - val_loss: 1.7845 - val_accuracy: 0.2292\n",
      "Epoch 15/45\n",
      "7/7 [==============================] - 60s 9s/step - loss: 1.3637 - accuracy: 0.4301 - val_loss: 1.7845 - val_accuracy: 0.2292\n",
      "Epoch 16/45\n",
      "7/7 [==============================] - 77s 11s/step - loss: 1.4012 - accuracy: 0.4420 - val_loss: 1.7190 - val_accuracy: 0.2292\n",
      "Epoch 17/45\n",
      "7/7 [==============================] - 63s 9s/step - loss: 1.3284 - accuracy: 0.4508 - val_loss: 1.7190 - val_accuracy: 0.2292\n",
      "Epoch 18/45\n",
      "7/7 [==============================] - 68s 10s/step - loss: 1.3453 - accuracy: 0.4404 - val_loss: 1.5962 - val_accuracy: 0.2292\n",
      "Epoch 19/45\n",
      "7/7 [==============================] - 64s 9s/step - loss: 1.4248 - accuracy: 0.4870 - val_loss: 1.5962 - val_accuracy: 0.2292\n",
      "Epoch 20/45\n",
      "7/7 [==============================] - 66s 9s/step - loss: 1.4169 - accuracy: 0.4375 - val_loss: 1.6670 - val_accuracy: 0.2917\n",
      "Epoch 21/45\n",
      "7/7 [==============================] - 53s 8s/step - loss: 1.2915 - accuracy: 0.4922 - val_loss: 1.6670 - val_accuracy: 0.2917\n",
      "Epoch 22/45\n",
      "7/7 [==============================] - 57s 8s/step - loss: 1.1666 - accuracy: 0.5440 - val_loss: 1.7565 - val_accuracy: 0.2500\n",
      "Epoch 23/45\n",
      "7/7 [==============================] - 62s 9s/step - loss: 1.1070 - accuracy: 0.5285 - val_loss: 1.7565 - val_accuracy: 0.2500\n",
      "Epoch 24/45\n",
      "7/7 [==============================] - 67s 10s/step - loss: 1.2687 - accuracy: 0.4715 - val_loss: 1.6076 - val_accuracy: 0.2083\n",
      "Epoch 25/45\n",
      "7/7 [==============================] - 61s 9s/step - loss: 1.1535 - accuracy: 0.4767 - val_loss: 1.6076 - val_accuracy: 0.2083\n",
      "Epoch 26/45\n",
      "7/7 [==============================] - 67s 10s/step - loss: 1.1108 - accuracy: 0.5181 - val_loss: 1.5572 - val_accuracy: 0.2292\n",
      "Epoch 27/45\n",
      "7/7 [==============================] - 73s 10s/step - loss: 1.1332 - accuracy: 0.5536 - val_loss: 1.5572 - val_accuracy: 0.2292\n",
      "Epoch 28/45\n",
      "7/7 [==============================] - 67s 10s/step - loss: 1.0376 - accuracy: 0.5078 - val_loss: 1.6566 - val_accuracy: 0.2917\n",
      "Epoch 29/45\n",
      "7/7 [==============================] - 54s 8s/step - loss: 1.1285 - accuracy: 0.5062 - val_loss: 1.6566 - val_accuracy: 0.2917\n",
      "Epoch 30/45\n",
      "7/7 [==============================] - 75s 11s/step - loss: 1.1942 - accuracy: 0.5134 - val_loss: 2.1594 - val_accuracy: 0.2083\n",
      "Epoch 31/45\n",
      "7/7 [==============================] - 66s 9s/step - loss: 0.9577 - accuracy: 0.5699 - val_loss: 2.1594 - val_accuracy: 0.2083\n",
      "Epoch 32/45\n",
      "7/7 [==============================] - 68s 10s/step - loss: 1.0483 - accuracy: 0.5803 - val_loss: 1.9600 - val_accuracy: 0.2292\n",
      "Epoch 33/45\n",
      "7/7 [==============================] - 64s 9s/step - loss: 0.9313 - accuracy: 0.5855 - val_loss: 1.9600 - val_accuracy: 0.2292\n",
      "Epoch 34/45\n",
      "7/7 [==============================] - 67s 10s/step - loss: 0.8695 - accuracy: 0.6010 - val_loss: 1.9887 - val_accuracy: 0.1458\n",
      "Epoch 35/45\n",
      "7/7 [==============================] - 69s 10s/step - loss: 1.0416 - accuracy: 0.5982 - val_loss: 1.9887 - val_accuracy: 0.1458\n",
      "Epoch 36/45\n",
      "7/7 [==============================] - 53s 8s/step - loss: 0.8330 - accuracy: 0.6235 - val_loss: 2.6730 - val_accuracy: 0.2500\n",
      "Epoch 37/45\n",
      "7/7 [==============================] - 67s 10s/step - loss: 0.9964 - accuracy: 0.6429 - val_loss: 2.6730 - val_accuracy: 0.2500\n",
      "Epoch 38/45\n",
      "7/7 [==============================] - 58s 8s/step - loss: 1.1212 - accuracy: 0.5123 - val_loss: 2.0286 - val_accuracy: 0.3125\n",
      "Epoch 39/45\n",
      "7/7 [==============================] - 67s 10s/step - loss: 1.0700 - accuracy: 0.5670 - val_loss: 2.0286 - val_accuracy: 0.3125\n",
      "Epoch 40/45\n",
      "7/7 [==============================] - 68s 10s/step - loss: 0.9200 - accuracy: 0.5596 - val_loss: 1.8748 - val_accuracy: 0.1458\n",
      "Epoch 41/45\n",
      "7/7 [==============================] - 65s 9s/step - loss: 0.9088 - accuracy: 0.6269 - val_loss: 1.8748 - val_accuracy: 0.1458\n",
      "Epoch 42/45\n",
      "4/7 [================>.............] - ETA: 33s - loss: 0.9557 - accuracy: 0.6484"
     ]
    }
   ],
   "source": [
    "step_size_train = train_it.n//train_it.batch_size #np.ceil((train_it.n//train_it.batch_size)/2)\n",
    "\n",
    "history = model.fit_generator(generator=train_it,\n",
    "                                  validation_data=validate_it,\n",
    "                                  validation_freq=2,\n",
    "                                  steps_per_epoch=step_size_train,\n",
    "                                  shuffle=True,\n",
    "                                  epochs=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test image \n",
    "test_it = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "test_it = test_it.flow_from_directory('data/images/test/',\n",
    "                                     target_size=(224,224),\n",
    "                                     color_mode='rgb',\n",
    "                                     batch_size=32,\n",
    "                                     class_mode='categorical',\n",
    "                                     shuffle=True,\n",
    "                                     classes=['assault_rifles','grenade_launchers','pistols','shotguns','sniper_rifles']\n",
    "                                     )\n",
    "\n",
    "test_batchX, test_batchy = test_it.next()\n",
    "\n",
    "print(\"labels: \", test_it.class_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.predict(test_it)\n",
    "\n",
    "for row in range(len(result)):\n",
    "    biggest = np.argmax(result[row])\n",
    "    for val in range(len(result[row])):\n",
    "        if(val == biggest):\n",
    "            result[row][val] = 1.\n",
    "        else:\n",
    "            result[row][val] = 0.\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot function, used to plot images with labels \n",
    "def plots(ims, figsize=(12,6), rows=2, interp=False, titles=None):\n",
    "    if type(ims[0]) is np.ndarray:\n",
    "        ims= np.array(ims).astype(np.uint8)\n",
    "        if (ims.shape[-1] != 3):\n",
    "            ims = ims.transpose((0,2,3,1))\n",
    "    f = plt.figure(figsize=figsize)\n",
    "    cols = len(ims)//rows if len(ims) % 2 == 0 else len(ims)//rows + 1\n",
    "    for i in range(len(ims)):\n",
    "        sp = f.add_subplot(rows, cols, i+1)\n",
    "        sp.axis('off')\n",
    "        if titles is not None:\n",
    "            sp.set_title(titles[i], fontsize=15)\n",
    "        plt.imshow(ims[i], interpolation=None if interp else 'none')\n",
    "\n",
    "# we plot these samples of images and their labels 1 batch at a time.\n",
    "plots(test_batchX, titles=result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
